{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f481860c",
   "metadata": {},
   "source": [
    "### Load the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b82eb7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import re\n",
    "# import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "288b167a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary libraries\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b441889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secondary libraries\n",
    "from tqdm import tqdm\n",
    "# from scipy import stats\n",
    "import scipy\n",
    "# from glob import glob\n",
    "import os\n",
    "# from matplotlib import dates as mpl_dates\n",
    "# import datetime\n",
    "# from datetime import date\n",
    "# import matplotlib.patches as mpatches\n",
    "# from matplotlib import cm\n",
    "# from colorspacious import cspace_converter\n",
    "# from collections import OrderedDict\n",
    "# import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea9594a",
   "metadata": {},
   "source": [
    "### Load the files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fca48fc",
   "metadata": {},
   "source": [
    "We are dealing with .gb files with single records each.\n",
    "\n",
    "From (https://warwick.ac.uk/fac/sci/moac/people/students/peter_cock/python/genbank/)-\n",
    "\n",
    "    Depending on the type of GenBank file(s) you are interested in, they will either contain a single record, or multiple records. You can easily determine this by looking at the raw file - each record will start with a LOCUS line, followed by various other header lines, usually a list of features, the sequence data, and ends with a // line (slash slash)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d11e63",
   "metadata": {},
   "source": [
    "Locations provided by **BioPython** is optimum for python purposes.\n",
    "- start and end provided by it are 1938 and 3075 respectively (0-based indexing and it assumes that end position is not included),\n",
    "- while in our actual file it is 1939 and 3075 (1-based indexing and it assumes that both start and end positions are included).\n",
    "\n",
    "This way we can directly slice seq string using locations provided to obtain the seq for the features of our interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87de23a",
   "metadata": {},
   "source": [
    "### Extracting desirable information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0e198c",
   "metadata": {},
   "source": [
    "Useful videos for the analysis done later-\n",
    "1. https://www.youtube.com/watch?v=LdQV3cbUwEE&list=PLe1-kjuYBZ05T9iHV_z60B9mpFt201ND5&index=8\n",
    "2. https://www.youtube.com/watch?v=HP7ThAj_f1E\n",
    "\n",
    "_Both videos are on Youtube @Bioinformatics Coach_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc6b423",
   "metadata": {},
   "source": [
    "KeyError resolution -\n",
    "\n",
    "    gene_name = gene.qualifiers['gene'][0]\n",
    "    gene_name = gene.qualifiers.get('gene',['unavailable'])[0]\n",
    "\n",
    "_Source_: https://bioinformatics.stackexchange.com/questions/15454/keyerror-when-getting-features-from-a-genbank-file-with-biopython-with-some-acce/15456#15456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "304066eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genbank_file_reader(file_name):\n",
    "    \"\"\"Takes in genbank file name in the folder ./genbank_files/;\n",
    "    Outputs the dataframe for that genbank file\n",
    "    \"\"\"\n",
    "    gb_record = SeqIO.read(open(f\"./genbank_files/{file_name}\", 'r'), 'genbank')\n",
    "    print(f'Name {gb_record.name}, {len(gb_record.features)} features')\n",
    "    \n",
    "    data = []\n",
    "\n",
    "    allgenes = (\n",
    "        feature\n",
    "        for feature in gb_record.features\n",
    "        if feature.type == 'gene'\n",
    "    )\n",
    "\n",
    "    for gene in allgenes:\n",
    "\n",
    "        gene_name = gene.qualifiers.get('gene',['unavailable'])[0]\n",
    "#         gene_ID = gene.qualifiers['db_xref'][0][7:]\n",
    "        gene_ID = gene.qualifiers.get('db_xref', ['GeneID:unavailable'])[0][7:]        \n",
    "        start_pos = gene.location.nofuzzy_start\n",
    "    #     start_pos = gene.location.nofuzzy_start + 1 # if 1-based indexing required\n",
    "        end_pos = gene.location.nofuzzy_end\n",
    "        strand_sense = gene.strand\n",
    "\n",
    "        gene_seq = gene.extract(gb_record).seq\n",
    "\n",
    "    #     For +ve sense strand\n",
    "        if strand_sense == 1:\n",
    "            if len(gb_record.seq[:start_pos]) >= 200:\n",
    "                upstream_flank = gb_record.seq[start_pos-200:start_pos]\n",
    "            else:\n",
    "                upstream_flank = gb_record.seq[:start_pos]\n",
    "\n",
    "            if len(gb_record.seq[end_pos:]) >= 200:\n",
    "                downstream_flank = gb_record.seq[end_pos:end_pos+200]\n",
    "            else:\n",
    "                downstream_flank = gb_record.seq[end_pos:]\n",
    "    #     For -ve sense strand\n",
    "        elif strand_sense == -1:\n",
    "            if len(gb_record.seq[:start_pos]) >= 200:\n",
    "                downstream_flank = gb_record.seq[start_pos-200:start_pos].reverse_complement()\n",
    "            else:\n",
    "                downstream_flank = gb_record.seq[:start_pos].reverse_complement()\n",
    "\n",
    "            if len(gb_record.seq[end_pos:]) >= 200:\n",
    "                upstream_flank = gb_record.seq[end_pos:end_pos+200].reverse_complement()\n",
    "            else:\n",
    "                upstream_flank = gb_record.seq[end_pos:].reverse_complement()\n",
    "    \n",
    "    # Addition starts ---------------------------------------------------------------\n",
    "    #     For +ve sense strand\n",
    "        if strand_sense == 1:\n",
    "            if len(gb_record.seq[:start_pos]) >= 203:\n",
    "                upstream_flank_203 = gb_record.seq[start_pos-200:start_pos+3]\n",
    "            else:\n",
    "                upstream_flank_203 = gb_record.seq[:start_pos+3]\n",
    "\n",
    "            if len(gb_record.seq[end_pos:]) >= 203:\n",
    "                downstream_flank_203 = gb_record.seq[end_pos:end_pos+203]\n",
    "            else:\n",
    "                downstream_flank_203 = gb_record.seq[end_pos:]\n",
    "    #     For -ve sense strand\n",
    "        elif strand_sense == -1:\n",
    "            if len(gb_record.seq[:start_pos]) >= 203:\n",
    "                downstream_flank_203 = gb_record.seq[start_pos-203:start_pos].reverse_complement()\n",
    "            else:\n",
    "                downstream_flank_203 = gb_record.seq[:start_pos].reverse_complement()\n",
    "\n",
    "            if len(gb_record.seq[end_pos:]) >= 203:\n",
    "                upstream_flank_203 = gb_record.seq[end_pos-3:end_pos+200].reverse_complement()\n",
    "            else:\n",
    "                upstream_flank_203 = gb_record.seq[end_pos-3:].reverse_complement()                \n",
    "    # Addition ends ---------------------------------------------------------------            \n",
    "                \n",
    "        data.append((gene_ID, gene_name, start_pos, end_pos, strand_sense, \n",
    "                     str(gene_seq), str(upstream_flank), str(downstream_flank), \n",
    "                     str(upstream_flank_203), str(downstream_flank_203)))    \n",
    "\n",
    "\n",
    "    # Creating an empty dataframe\n",
    "    df = pd.DataFrame(data, columns=['gene_ID', \n",
    "                                     'gene_name', \n",
    "                                     'start_position', \n",
    "                                     'end_position', \n",
    "                                     'strand_sense', \n",
    "                                     'gene_seq', \n",
    "                                     'upstream_flank', \n",
    "                                     'downstream_flank', \n",
    "                                     'upstream_flank_203', \n",
    "                                     'downstream_flank_203'])\n",
    "# #     Saving the dataframe to a .csv file\n",
    "    df.to_csv('./csv_files_for_promoters/consensus01_'+file_name[:-3]+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ca22c0",
   "metadata": {},
   "source": [
    "How to iterate over a given directory:\n",
    "https://stackoverflow.com/questions/10377998/how-can-i-iterate-over-files-in-a-given-directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39b2b522",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "escherichia_coli_BW25113.gb\n",
      "Name CP009273, 9462 features\n",
      "bacillus_subtilis.gb\n",
      "Name NC_000964, 9074 features\n",
      "streptococcus_pneumoniae.gb\n",
      "Name NZ_CP020549, 4328 features\n",
      "klebsiella_pneumoniae.gb\n",
      "Name NC_016845, 10894 features\n"
     ]
    }
   ],
   "source": [
    "# To do the flank calculations for all files\n",
    "directory = os.fsencode('./genbank_files/')\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith('.gb'):\n",
    "        print(filename)\n",
    "        genbank_file_reader(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b42d05",
   "metadata": {},
   "source": [
    "### Loading the csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "84a6a1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: -200, 2: -199, 3: -198, 4: -197, 5: -196, 6: -195, 7: -194, 8: -193, 9: -192, 10: -191, 11: -190, 12: -189, 13: -188, 14: -187, 15: -186, 16: -185, 17: -184, 18: -183, 19: -182, 20: -181, 21: -180, 22: -179, 23: -178, 24: -177, 25: -176, 26: -175, 27: -174, 28: -173, 29: -172, 30: -171, 31: -170, 32: -169, 33: -168, 34: -167, 35: -166, 36: -165, 37: -164, 38: -163, 39: -162, 40: -161, 41: -160, 42: -159, 43: -158, 44: -157, 45: -156, 46: -155, 47: -154, 48: -153, 49: -152, 50: -151, 51: -150, 52: -149, 53: -148, 54: -147, 55: -146, 56: -145, 57: -144, 58: -143, 59: -142, 60: -141, 61: -140, 62: -139, 63: -138, 64: -137, 65: -136, 66: -135, 67: -134, 68: -133, 69: -132, 70: -131, 71: -130, 72: -129, 73: -128, 74: -127, 75: -126, 76: -125, 77: -124, 78: -123, 79: -122, 80: -121, 81: -120, 82: -119, 83: -118, 84: -117, 85: -116, 86: -115, 87: -114, 88: -113, 89: -112, 90: -111, 91: -110, 92: -109, 93: -108, 94: -107, 95: -106, 96: -105, 97: -104, 98: -103, 99: -102, 100: -101, 101: -100, 102: -99, 103: -98, 104: -97, 105: -96, 106: -95, 107: -94, 108: -93, 109: -92, 110: -91, 111: -90, 112: -89, 113: -88, 114: -87, 115: -86, 116: -85, 117: -84, 118: -83, 119: -82, 120: -81, 121: -80, 122: -79, 123: -78, 124: -77, 125: -76, 126: -75, 127: -74, 128: -73, 129: -72, 130: -71, 131: -70, 132: -69, 133: -68, 134: -67, 135: -66, 136: -65, 137: -64, 138: -63, 139: -62, 140: -61, 141: -60, 142: -59, 143: -58, 144: -57, 145: -56, 146: -55, 147: -54, 148: -53, 149: -52, 150: -51, 151: -50, 152: -49, 153: -48, 154: -47, 155: -46, 156: -45, 157: -44, 158: -43, 159: -42, 160: -41, 161: -40, 162: -39, 163: -38, 164: -37, 165: -36, 166: -35, 167: -34, 168: -33, 169: -32, 170: -31, 171: -30, 172: -29, 173: -28, 174: -27, 175: -26, 176: -25, 177: -24, 178: -23, 179: -22, 180: -21, 181: -20, 182: -19, 183: -18, 184: -17, 185: -16, 186: -15, 187: -14, 188: -13, 189: -12, 190: -11, 191: -10, 192: -9, 193: -8, 194: -7, 195: -6, 196: -5, 197: -4, 198: -3, 199: -2, 200: -1}\n"
     ]
    }
   ],
   "source": [
    "mapping_dict = {}\n",
    "\n",
    "mapping_values_list = [i for i in range(-200, 0, 1)]\n",
    "mapping_keys_list = [i for i in range(1, 201, 1)]\n",
    "\n",
    "for i in range(len(mapping_keys_list)):\n",
    "    mapping_dict[mapping_keys_list[i]] = mapping_values_list[i]\n",
    "    \n",
    "print(mapping_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303bdbf4",
   "metadata": {},
   "source": [
    "How to iterate rows of a dataframe: https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b6d1174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def motif_analysis(df, file_name):\n",
    "    \"\"\"Input: dataframe loaded from csv file and its file name\n",
    "    Output: dataframes for upstream- and downstream- flank's motif analysis\n",
    "    \"\"\"\n",
    "    upstream_dict = {}\n",
    "    downstream_dict = {}\n",
    "    for key in keys_list:\n",
    "        upstream_dict[key] = 0\n",
    "        downstream_dict[key] = 0\n",
    "\n",
    "    # make sure indexes pair with number of rows\n",
    "    df = df.reset_index()\n",
    "    for index, row in df.iterrows():\n",
    "        # pd.isnull statements were added to handle the cases with no flank regions\n",
    "        if not pd.isnull(row['upstream_flank_203']):\n",
    "            for m in re.finditer(pattern, row['upstream_flank_203']):\n",
    "                upstream_dict[m.start()+1] += 1\n",
    "        if not pd.isnull(row['downstream_flank_203']):\n",
    "            for m in re.finditer(pattern, row['downstream_flank_203']):\n",
    "                downstream_dict[m.start()+1] += 1\n",
    "    \n",
    "    mapped_upstream_dict = {}\n",
    "    for key in upstream_dict:\n",
    "        mapped_upstream_dict[mapping_dict[key]] = upstream_dict[key]    \n",
    "    \n",
    "    df_up = pd.DataFrame.from_dict(mapped_upstream_dict, orient='index')\n",
    "    df_down = pd.DataFrame.from_dict(downstream_dict, orient='index')\n",
    "    df_up.to_csv('./csv_files_for_promoters_consensus_motifs/consensus01_upstream_'+file_name[12:])\n",
    "    df_down.to_csv('./csv_files_for_promoters_consensus_motifs/consensus01_downstream_'+file_name[12:])\n",
    "    del df_up, df_down\n",
    "#         print(row['upstream_flank'], '\\n\\n' , row['downstream_flank'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29d81559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consensus01_streptococcus_pneumoniae.csv\n",
      "2157\n",
      "consensus01_escherichia_coli_BW25113.csv\n",
      "4490\n",
      "consensus01_bacillus_subtilis.csv\n",
      "4536\n",
      "consensus01_klebsiella_pneumoniae.csv\n",
      "5404\n"
     ]
    }
   ],
   "source": [
    "keys_list = [i for i in range(1, 201)]\n",
    "pattern = re.compile(r'T[AT]AT')\n",
    "\n",
    "# To do the flank calculations for all files\n",
    "directory = os.fsencode('./csv_files_for_promoters/')\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "#     print(filename)\n",
    "    if filename.startswith('consensus01') and filename.endswith('.csv'):\n",
    "        print(filename)\n",
    "        df_temp = pd.read_csv('./csv_files_for_promoters/'+filename)\n",
    "        print(len(df_temp.index))\n",
    "        motif_analysis(df_temp, filename)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
